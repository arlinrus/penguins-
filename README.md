# Предположение о характере взаимосвязи факторов и результата.

Данные и гипотезы исследования:

Воспользуемся датасетом с сайта : **https://huggingface.co/datasets/SIH/palmer-penguins**

В данном датасете содержаться сведения об Антарктических пингвинах

![penguins_map](https://github.com/arlinrus/penguins-/assets/111064731/c888f21a-f49c-4579-9c0e-1e3d6ec6373f)

Случайных событий - 344

species - вид пингвина (качественная переменная)

**island** - остров, где находятся определенная порода пингвина (качественная переменная)

**bill_length_mm** - длина клюва пингвина (непрерывные количественные)

**bill_depth_mm** - глубина ключа пингвина (непрерывные количественные)

**flipper_length_mm** - длина крыла пингвина (непрерывные количественные)

**body_mass_g** - масса тела пингвина (непрерывные количественные)

**sex** - пол пингвина (качественная переменная)

**year** - возраст пингвина (количественная переменная)

Проведем анализ полученных данных и получим датасет, состоящий из столбцов: **bill_length_mm, bill_depth_mm,	flipper_length_mm,	body_mass_g,	sex,	year**, где sex заменим на 1 - female и 0 - male. Также уберем пустые значения, чтобы не было лишних выбросов.

Для того, чтобы проверить данные на наличие выбросов построим **boxplot** для каждого значения столбца с полом пингвина.

![Unknown-3](https://github.com/arlinrus/penguins-/assets/111064731/15018313-a3ed-4df6-b981-199d7c565af9)


![Unknown](https://github.com/arlinrus/penguins-/assets/111064731/529e3212-84c0-4556-b559-6eb7fe5cea63)

![Unknown-1](https://github.com/arlinrus/penguins-/assets/111064731/1f5e2e1c-a3ae-4bff-8c24-114301b0177f)


![Unknown-2](https://github.com/arlinrus/penguins-/assets/111064731/cc539091-eb0c-4bce-ab3a-07509c0140f6)



Убедившись, что для KPA нету противоречий, переходим к анализу.

## Анализ корреляции

### Проверим данные на нормальность распределения по тесту Шапиро Уилка, если значения отклоняются от 0,5 в меньшую сторону, то надо проверять на нормальность распределения.

Для начала про логорифмируем данные, для более точного и плавного построения графика.

```
data[1] = np.log(data[1])
data[2] = np.log(data[2])

```

#### График без логорифмирования данных

![Unknown](https://github.com/arlinrus/penguins-/assets/111064731/8ec3dba8-b1af-47b4-b508-7ca44cdd0f39)


### Рассмотрим матрицу корреляции, которая показывает связь между данными:


![Unknown-2](https://github.com/arlinrus/penguins-/assets/111064731/aebb4ba8-9c00-49b1-a9e5-089aad1bed67)


Получим, что данные, имеют нормальное распределения по тесту.

Вычислим коэффициент корреляции Пирсона(линейный коэффициент корреляции)

1)Между переменными 'bill_length_mm' и 'flipper_length_mm' существует сильная положительная корреляция (коэффициент корреляции примерно равен 0.65).

2)Между переменными 'bill_length_mm' и 'body_mass_g' также существует сильная положительная корреляция (коэффициент корреляции примерно равен 0.59).

3)Между переменными 'bill_depth_mm' и 'flipper_length_mm' существует умеренная отрицательная корреляция (коэффициент корреляции примерно равен -0.58).

4)Между переменными 'bill_depth_mm' и 'body_mass_g' также существует умеренная отрицательная корреляция (коэффициент корреляции примерно равен -0.48).


![download](https://github.com/arlinrus/penguins-/assets/111064731/f33fd365-ec39-4450-bbb7-67b243a2c07d)

![download](https://github.com/arlinrus/penguins-/assets/111064731/e134e41e-1e8e-4d04-a625-a9af8deb70b5)

![download](https://github.com/arlinrus/penguins-/assets/111064731/201d65c9-fa96-4308-8b27-d5de2aaa208c)

![download](https://github.com/arlinrus/penguins-/assets/111064731/7a6e85f0-b995-4305-a76c-7a275bc1228a)



### Вычислим коэффициенты b1 и b0 для уравнения линейной регрессии:
Сравним данные длины и шлубины клюа, где глубина - зависимая переменная.  

```
x1 = pgns['bill_length_mm']
y1 = pgns['bill_depth_mm']

mean_x = sum(x1)/len(x1)
mean_y = sum(y1)/len(y1)

covariance = sum((xi-mean_x)*yi-mean_y for xi, yi in zip(x1, y1))
variance = sum((xi - mean_x)**2 for xi in x1)

b1 = covariance / variance
b0 = mean_y - b1*mean_x
```

<dl>
  <dt>Таким образом получим следующие рзультаты:
</dt>
  <dd>b1 - наклон линии:  -0.6580097035844675
    
b0 - интерсепт 46.112549410303366

Уравнение линейной регрессии: y = 46.11 + -0.66*x1</dd>
</dl>

### Визуализируем график

![Unknown](https://github.com/arlinrus/penguins-/assets/111064731/561ff00f-7be3-426e-abdf-5d3c6d8f51a8)

### Рассчитаем множественную модель(корреляция) - показывает, насколько хорошо комбинация независимых переменных объясняет вариацию зависимой переменной.

```
a = peng['bill_length_mm']
b = peng['bill_depth_mm']

corr_coef = np.corrcoef(a,b)
mult_corr = corr_coef[-1: 1]
mult_corr = np.sqrt(np.prod(mult_corr**2))

```

### Рассчитаем объясненную и необъясненную дисперсию
SSR - регрессионный анализ

SSE - ошибка суммы
```
x2 = np.array(pgns['bill_length_mm'])
y2 = np.array(pgns['bill_depth_mm'])

y_pred = b0 + b1*x1

y_mean = np.mean(y2)

#Объясненная дисперсия SSR(регресионный анализ)
SSR = np.sum((y_pred - y_mean)**2)

#Необъясненная дисперсия SSE(ошибка суммы квадратов)
SSE = np.sum((y2 - y_pred)**2)

sum_desp = int(SSR)+ int(SSE)

```
<dl>
  <dt>Получим следующие результаты</dt>
  <dd>Объясненная дисперсия:  4298.98422197287
    
Необъясненная дисперсия:  4510.710026383096

Сумма:  8808</dd>
</dl>

### Коэффициент детерминации
```
r_2 = SSR / sum_desp 

```
⋅⋅В 34.2% случаев изменения х приводят к изменению y.
Другими словами - точность подбора уравнения регрессии низкая.
Остальные 65.8% изменения Y объясняются факторами, не учтенными в модели.

***Коэффициент детерминации показывает обратную связь между зависимой переменной (y) и независимой переменной (x), увеличение x связано с уменьшением значения  y :  0.4880772277444221***

### Оценка значимости уравнения в целом(F - критерий Фишера)

где F - критерий для проверки гипотезы H0: MSR = MSE

```
n = len(np.array(pgns['flipper_length_mm']))
k = 1
#Дисперсия на 1 степень свободы, факторная - msr
#Дисперсия на 1 степень свободы, остаточная - mse
msr = SSR/k
mse = SSE/(n-k-1)

F = msr/mse

if F > 3.86:
  print(f'F - критерий Фишера: {F}, модель значимая')
else:
  print(f'F - критерий Фишера: {F}, модель Не значимая')
```
<dl>
  <dt>Получим следующие результаты</dt>
  <dd>
    F - критерий Фишера: 315.4633681061561.
    Так как 315 > 3.86, то модель признается значимой
  </dd>
</dl>

### Проведем оценку значимости параметра(t-критерий Стьюдента) - определяет статистическую значимость различий средних величин.
Для начала найдем SSX - сумма квадртов отклонений среднего значения от x
```
x1 = np.array(pgns['bill_length_mm'])
x1_mean = x1.mean()
SSX = np.sum((x1-x1_mean)**2)
```
<dl>
  <dt>Получим следующие результаты</dt>
  <dd>
  9928.902702702702
  </dd>
</dl>

Далее найдем стандартную ошибку оценка Syx
```
x_values = np.array(pgns['bill_length_mm'])
x_mean = np.array(x_values)
#Стандартное отклонение остатков
S_E = np.sqrt(SSR/(333-2))

#Стандартная ошибка оценка
S_YX = S_E * np.sqrt(1-(1/333)-((x_values-x_mean)**2)/SSX)
```
<dl>
  <dt>Получим следующие результаты</dt>
  <dd>
    
    Стандартное отклонение остатков:  3.6038684410088146

    Стандартная ошибка оценки: 3.59845316 - это оценка того, как значение статистика критерия меняется от выборки к выборке.
  </dd>
</dl>


### Оценка существенности ошибки корреляции 
Показывает корреляционная связь
```
R_XY = np.sqrt(r_2)
```
### Гомоскедантичность остатков

Гомоскедастичность остатков в линейной регрессии означает, что дисперсия остатков (разниц между фактическими значениями зависимой переменной и предсказанными значениями, полученными с помощью модели) остается const (неизменной) по всем значениям независимой переменной. Другими словами, это означает, что разброс ошибок модели одинаков для всех уровней независимой переменной.


![IMAGE 2024-05-16 00:27:00](https://github.com/arlinrus/penguins-/assets/111064731/e87b289a-04e6-45a1-abea-6aa2321fd1c0)



### Ошибка аппроксимации - показывает отклонение реальных данных от фактических.


**Её мы решили высчитать с помощью данных из таблицы Excel**



**https://docs.google.com/spreadsheets/d/11jl65RG5bq_B9jB2fL5kEbNQmXPClRFpGG5gp--5yoE/edit#gid=1066452339**

<dl>
  <dt>Получим следующие результаты</dt>
  <dd>
    Ошибка аппроксимации получилась: 16,98 Ю > 15% , что говорит о неправильности об отклонении рельаных данных от фактических.
  </dd>
</dl>

---
Таким образом мы рассмотрели данные о длине, глубине клюва пингвина, длину его крыльев, пол и др. выборки. Постарались выявить зависимость между 2 переменнами 


